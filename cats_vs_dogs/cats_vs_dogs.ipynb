{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from numpy import load\n",
    "\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.image import imread\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, BatchNormalization, Dropout\n",
    "from keras.optimizers import SGD, Adadelta, Adam, Adagrad\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.initializers import HeNormal, GlorotUniform\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "from tensorboard import notebook\n",
    "import tensorflow_addons as tfa\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pip install keras\n",
    "#!pip install tensorflow-addons\n",
    "#!pip install -q pyyaml h5py \n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "notebook.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dataset, reshaping and saving to .npy\n",
    "#### Using kaggle.com cats_vs_dogs dataset, only \"train\" folder is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading dataset, reshaping and saving to \n",
    "from os import listdir\n",
    "from numpy import asarray\n",
    "from numpy import save\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "# define location of dataset\n",
    "folder = 'train/'\n",
    "photos, labels = list(), list()\n",
    "# enumerate files in the directory\n",
    "for file in listdir(folder):\n",
    "  # determine class\n",
    "    output = 0.0\n",
    "    if file.startswith('cat'):\n",
    "        output = 1.0\n",
    "  # load image\n",
    "    photo = load_img(folder + file, target_size=(200, 200))\n",
    "  # convert to numpy array\n",
    "    photo = img_to_array(photo)\n",
    "  # store\n",
    "    photos.append(photo)\n",
    "    labels.append(output)\n",
    "# convert to a numpy arrays\n",
    "photos = asarray(photos)\n",
    "labels = asarray(labels)\n",
    "print(photos.shape, labels.shape)\n",
    "# save the reshaped photos\n",
    "save('dogs_vs_cats_photos.npy', photos)\n",
    "save('dogs_vs_cats_labels.npy', labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading .npy in variables (12 GB RAM required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### loading dataset into variables in one run + normalization\n",
    "train_set, valid_set, train_labels, valid_labels = train_test_split(load('dogs_vs_cats_photos.npy').reshape(25000, 120000) / 255.0, load('dogs_vs_cats_labels.npy'), train_size=0.8, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard init + short info about the structure of all available models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### MODEL INFO\n",
    "# model1 - 1 sigmoid norm init + SGD\n",
    "# model2 - 1 relu He init + 1 sigmoid norm init + SGD\n",
    "# model3 - 3 relu He init + sigmoid He + SGD\n",
    "# model4 - 4 tanh GlorotUniform init + sigmoid GlorotUniform init + SGD\n",
    "# model5 - 4 elu He init + sigmoid He init + SGD\n",
    "# model6 - 4 elu He init + sigmoid He init + Adadelta\n",
    "# model7 - 4 elu He init + sigmoid He init + Adam\n",
    "# model8 - 4 elu He init + sigmoid He init + Adagrad\n",
    "# model11 - 5 elu He init + sigmoid He init + Adadelta\n",
    "# model12 - 4 elu He init + sigmoid He init + Adadelta + Batch norm\n",
    "# model13 - 4 elu He init + sigmoid He init + Adadelta + Dropout + Batch norm\n",
    "# model14 - 4 leaky relu He init + sigmoid He init + Adadelta\n",
    "# model15 - 4 param relu He init + sigmoid He init + Adadelta\n",
    "# model16 - 4 elu He init + sigmoid He init + Adadelta + Dropout + Batch norm + l1 l2 + max norm + Early Stop\n",
    "# model17 - 4 leaky relu He init + sigmoid He init + Adadelta + Batch norm + Dropout + Early Stop\n",
    "# model18 - 4 leaky relu He init + sigmoid He init + Adadelta + Batch norm + Dropout + l1 l2 + Early Stop\n",
    "\n",
    "%tensorboard --logdir logs --host localhost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom metric F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 - sigmoid norm init + SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model():     ### sigmoid only\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_initializer=RandomNormal(mean=0., stddev=1.)))\n",
    "    # compile model\n",
    "    opt = SGD()\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy', 'AUC', f1])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### model 1, simplest 1 sigmoid, normal init\n",
    "model = define_model()\n",
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "log_dir = \"logs/model1/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_set, train_labels, validation_data = (valid_set, valid_labels), epochs=20, callbacks=[cp_callback, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### model 1\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### saving final model 1 \n",
    "#!mkdir -p saved_model\n",
    "model.save('saved_model/model1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 - 1 relu He init + 1 sigmoid norm init + SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model2():     ### one relu \n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, activation='relu', kernel_initializer=HeNormal()))\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_initializer=RandomNormal(mean=0., stddev=1.)))\n",
    "    # compile model\n",
    "    opt = SGD()\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy', 'AUC', f1])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### model 2, 1 relu + sigmoid, He + normal initializer\n",
    "model2 = define_model2()\n",
    "checkpoint_path2 = \"training_2/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path2)\n",
    "cp_callback2 = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path2,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "log_dir2 = \"logs/model2/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback2 = tf.keras.callbacks.TensorBoard(log_dir=log_dir2, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.fit(train_set, train_labels, validation_data = (valid_set, valid_labels), epochs=20, callbacks=[cp_callback2, tensorboard_callback2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save('saved_model/model2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3 - 3 relu He init + sigmoid He + SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model3():     ### 3 relu\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, activation='relu', kernel_initializer=HeNormal()))\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer=HeNormal()))\n",
    "    model.add(Dense(64, activation='relu', kernel_initializer=HeNormal()))\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_initializer=HeNormal()))\n",
    "    # compile model\n",
    "    opt = SGD()\n",
    "    model.compile(optimizer=opt, loss='y_p ', metrics=['accuracy', 'AUC', f1])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3 relu + sigmoid, He init everywhere\n",
    "model3 = define_model3()\n",
    "checkpoint_path3 = \"training_3/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path3)\n",
    "cp_callback3 = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path3,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "log_dir3 = \"logs/model3/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback3 = tf.keras.callbacks.TensorBoard(log_dir=log_dir3, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.fit(train_set, train_labels, validation_data = (valid_set, valid_labels), epochs=20, callbacks=[cp_callback3, tensorboard_callback3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.save('saved_model/model3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4 - 4 tanh GlorotUniform init + sigmoid GlorotUniform init + SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model4():     ### 4 tanh\n",
    "    model = Sequential()\n",
    "    #model.add(Dense(1084, kernel_initializer=GlorotUniform(), activation='tanh'))\n",
    "    #model.add(Dense(408, kernel_initializer=GlorotUniform(), activation='tanh'))\n",
    "    model.add(Dense(512, kernel_initializer=GlorotUniform(), activation='tanh'))\n",
    "    model.add(Dense(256, kernel_initializer=GlorotUniform(), activation='tanh'))\n",
    "    model.add(Dense(128, kernel_initializer=GlorotUniform(), activation='tanh'))\n",
    "    model.add(Dense(64, kernel_initializer=GlorotUniform(), activation='tanh'))\n",
    "    model.add(Dense(1, kernel_initializer=GlorotUniform(), activation='sigmoid'))\n",
    "    opt = SGD()\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy', 'AUC', f1])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4 tanh + sigmoid, Glorot init\n",
    "model4 = define_model4()\n",
    "checkpoint_path4 = \"training_4/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path4)\n",
    "cp_callback4 = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path4,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "log_dir4 = \"logs/model4/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback4 = tf.keras.callbacks.TensorBoard(log_dir=log_dir4, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.fit(train_set, train_labels, validation_data = (valid_set, valid_labels), epochs=20, callbacks=[cp_callback4, tensorboard_callback4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.save('saved_model/model4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5 - 4 elu He init + sigmoid He init + SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model5():     ### 4 elu\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, kernel_initializer=HeNormal(), activation='elu'))\n",
    "    model.add(Dense(256, kernel_initializer=HeNormal(), activation='elu'))\n",
    "    model.add(Dense(128, kernel_initializer=HeNormal(), activation='elu'))\n",
    "    model.add(Dense(64, kernel_initializer=HeNormal(), activation='elu'))\n",
    "    model.add(Dense(1, kernel_initializer=HeNormal(), activation='sigmoid'))\n",
    "    opt = SGD()\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy', 'AUC', f1])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4 elu + sigmoid, He init, SGD opt\n",
    "model5 = define_model5()\n",
    "checkpoint_path5 = \"training_5/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path5)\n",
    "cp_callback5 = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path5,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "log_dir5 = \"logs/model5/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback5 = tf.keras.callbacks.TensorBoard(log_dir=log_dir5, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5.fit(train_set, train_labels, validation_data = (valid_set, valid_labels), epochs=20, callbacks=[cp_callback5, tensorboard_callback5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5.save('saved_model/model5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 6 - 4 elu He init + sigmoid He init + Adadelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model6():     ### 4 elu\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, kernel_initializer=HeNormal(), activation='elu'))\n",
    "    model.add(Dense(256, kernel_initializer=HeNormal(), activation='elu'))\n",
    "    model.add(Dense(128, kernel_initializer=HeNormal(), activation='elu'))\n",
    "    model.add(Dense(64, kernel_initializer=HeNormal(), activation='elu'))\n",
    "    model.add(Dense(1, kernel_initializer=HeNormal(), activation='sigmoid'))\n",
    "    opt = Adadelta()\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy', 'AUC', f1])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4 elu + adadelta\n",
    "model6 = define_model6()\n",
    "checkpoint_path6 = \"training_6/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path6)\n",
    "cp_callback6 = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path6,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "log_dir6 = \"logs/model6/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback6 = tf.keras.callbacks.TensorBoard(log_dir=log_dir6, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6.fit(train_set, train_labels, validation_data = (valid_set, valid_labels), epochs=20, callbacks=[cp_callback6, tensorboard_callback6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6.save('saved_model/model6')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 7 - 4 elu He init + sigmoid He init + Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model7():     ### 5 elu\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, kernel_initializer=HeNormal(), activation='elu'))\n",
    "    model.add(Dense(256, kernel_initializer=HeNormal(), activation='elu'))\n",
    "    model.add(Dense(128, kernel_initializer=HeNormal(), activation='elu'))\n",
    "    model.add(Dense(64, kernel_initializer=HeNormal(), activation='elu'))\n",
    "    model.add(Dense(1, kernel_initializer=HeNormal(), activation='sigmoid'))\n",
    "    opt = Adam()\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy', 'AUC', f1])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4 elu + adam\n",
    "model7 = define_model7()\n",
    "checkpoint_path7 = \"training_7/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path7)\n",
    "cp_callback7 = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path7,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "log_dir7 = \"logs/model7/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback7 = tf.keras.callbacks.TensorBoard(log_dir=log_dir7, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model7.fit(train_set, train_labels, validation_data = (valid_set, valid_labels), epochs=20, callbacks=[cp_callback7, tensorboard_callback7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model7.save('saved_model/model7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 8 - 4 elu He init + sigmoid He init + Adagrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model8():     ### 5 elu\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, kernel_initializer=HeNormal(), activation='elu'))\n",
    "    model.add(Dense(256, kernel_initializer=HeNormal(), activation='elu'))\n",
    "    model.add(Dense(128, kernel_initializer=HeNormal(), activation='elu'))\n",
    "    model.add(Dense(64, kernel_initializer=HeNormal(), activation='elu'))\n",
    "    model.add(Dense(1, kernel_initializer=HeNormal(), activation='sigmoid'))\n",
    "    opt = Adagrad()\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy', 'AUC', f1])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4 elu + adagrad\n",
    "model8 = define_model8()\n",
    "checkpoint_path8 = \"training_8/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path8)\n",
    "cp_callback8 = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path8,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "log_dir8 = \"logs/model8/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback8 = tf.keras.callbacks.TensorBoard(log_dir=log_dir8, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model8.fit(train_set, train_labels, validation_data = (valid_set, valid_labels), epochs=20, callbacks=[cp_callback8, tensorboard_callback8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model8.save('saved_model/model8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 11 - 5 elu He init + sigmoid He init + Adadelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model11():     ### 5 elu\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1024, kernel_initializer=HeNormal(), activation='elu'))\n",
    "    model.add(Dense(512, kernel_initializer=HeNormal(), activation='elu'))\n",
    "    model.add(Dense(256, kernel_initializer=HeNormal(), activation='elu'))\n",
    "    model.add(Dense(128, kernel_initializer=HeNormal(), activation='elu'))\n",
    "    model.add(Dense(64, kernel_initializer=HeNormal(), activation='elu'))\n",
    "    model.add(Dense(1, kernel_initializer=HeNormal(), activation='sigmoid'))\n",
    "    opt = Adadelta()\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy', 'AUC', f1])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4 elu + adadelta\n",
    "model11 = define_model11()\n",
    "checkpoint_path11 = \"training_11/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path11)\n",
    "cp_callback11 = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path11,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "log_dir11 = \"logs/model11/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback11 = tf.keras.callbacks.TensorBoard(log_dir=log_dir11, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model11.fit(train_set, train_labels, validation_data = (valid_set, valid_labels), epochs=20, callbacks=[cp_callback11, tensorboard_callback11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model11.save('saved_model/model11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model11.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 12 - 4 elu He init + sigmoid He init + Adadelta + Batch norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model12():     ### 5 elu\n",
    "    model = Sequential()\n",
    "    #model.add(Dense(1024, kernel_initializer=HeNormal(), activation='elu'))\n",
    "    model.add(Dense(512, kernel_initializer=HeNormal(), activation='elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(256, kernel_initializer=HeNormal(), activation='elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(128, kernel_initializer=HeNormal(), activation='elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(64, kernel_initializer=HeNormal(), activation='elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1, kernel_initializer=HeNormal(), activation='sigmoid'))\n",
    "    opt = Adadelta()\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy', 'AUC', f1])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4 elu + adadelta * batch norm\n",
    "model12 = define_model12()\n",
    "checkpoint_path12 = \"training_12/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path12)\n",
    "cp_callback12 = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path12,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "log_dir12 = \"logs/model12/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback12 = tf.keras.callbacks.TensorBoard(log_dir=log_dir12, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model12.fit(train_set, train_labels, validation_data = (valid_set, valid_labels), epochs=20, callbacks=[cp_callback12, tensorboard_callback12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model12.save('saved_model/model12')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 13 - 4 elu He init + sigmoid He init + Adadelta + Dropout + Batch norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model13():     ### 5 elu\n",
    "    model = Sequential()\n",
    "    #model.add(Dense(1024, kernel_initializer=HeNormal(), activation='elu'))\n",
    "    model.add(Dense(512, kernel_initializer=HeNormal(), activation='elu'))\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(256, kernel_initializer=HeNormal(), activation='elu'))\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(128, kernel_initializer=HeNormal(), activation='elu'))\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(64, kernel_initializer=HeNormal(), activation='elu'))\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1, kernel_initializer=HeNormal(), activation='sigmoid'))\n",
    "    opt = Adadelta()\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy', 'AUC', f1])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4 elu + adadelta * batch norm\n",
    "model13 = define_model13()\n",
    "checkpoint_path13 = \"training_13/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path13)\n",
    "cp_callback13 = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path13,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "log_dir13 = \"logs/model13/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback13 = tf.keras.callbacks.TensorBoard(log_dir=log_dir13, histogram_freq=1)\n",
    "\n",
    "early_stop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model13.fit(train_set, train_labels, validation_data = (valid_set, valid_labels), epochs=30, callbacks=[cp_callback13, tensorboard_callback13, early_stop_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model13.save('saved_model/model13')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 14 - 4 leaky relu He init + sigmoid He init + Adadelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model14():     ### 4 elu\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, kernel_initializer=HeNormal(), activation=tf.keras.layers.LeakyReLU()))\n",
    "    model.add(Dense(256, kernel_initializer=HeNormal(), activation=tf.keras.layers.LeakyReLU()))\n",
    "    model.add(Dense(128, kernel_initializer=HeNormal(), activation=tf.keras.layers.LeakyReLU()))\n",
    "    model.add(Dense(64, kernel_initializer=HeNormal(), activation=tf.keras.layers.LeakyReLU()))\n",
    "    model.add(Dense(1, kernel_initializer=HeNormal(), activation='sigmoid'))\n",
    "    opt = Adadelta()\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy', 'AUC', f1])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4 elu + adadelta\n",
    "model14 = define_model14()\n",
    "checkpoint_path14 = \"training_14/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path14)\n",
    "cp_callback14 = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path14,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "log_dir14 = \"logs/model14/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback14 = tf.keras.callbacks.TensorBoard(log_dir=log_dir14, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model14.fit(train_set, train_labels, validation_data = (valid_set, valid_labels), epochs=20, callbacks=[cp_callback14, tensorboard_callback14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model14.save('saved_model/model14')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 15 - 4 param relu He init + sigmoid He init + Adadelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model15():     ### 4 elu\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, kernel_initializer=HeNormal(), activation=tf.keras.layers.PReLU()))\n",
    "    model.add(Dense(256, kernel_initializer=HeNormal(), activation=tf.keras.layers.PReLU()))\n",
    "    model.add(Dense(128, kernel_initializer=HeNormal(), activation=tf.keras.layers.PReLU()))\n",
    "    model.add(Dense(64, kernel_initializer=HeNormal(), activation=tf.keras.layers.PReLU()))\n",
    "    model.add(Dense(1, kernel_initializer=HeNormal(), activation='sigmoid'))\n",
    "    opt = Adadelta()\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy', 'AUC', f1])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4 elu + adadelta\n",
    "model15 = define_model15()\n",
    "checkpoint_path15 = \"training_15/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path15)\n",
    "cp_callback15 = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path15,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "log_dir15 = \"logs/model15/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback15 = tf.keras.callbacks.TensorBoard(log_dir=log_dir15, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model15.fit(train_set, train_labels, validation_data = (valid_set, valid_labels), epochs=20, callbacks=[cp_callback15, tensorboard_callback15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model15.save('saved_model/model15')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 16 - 4 elu He init + sigmoid He init + Adadelta + Dropout + Batch norm + l1 l2 + max norm + Early Stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model16():     ### 5 elu\n",
    "    model = Sequential()\n",
    "    #model.add(Dense(1024, kernel_initializer=HeNormal(), activation='elu'))\n",
    "    model.add(Dense(512, kernel_regularizer='l1_l2', kernel_constraint=tf.keras.constraints.MaxNorm(max_value=2, axis=0), kernel_initializer=HeNormal(), activation='elu'))\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(256, kernel_regularizer='l1_l2', kernel_constraint=tf.keras.constraints.MaxNorm(max_value=2, axis=0), kernel_initializer=HeNormal(), activation='elu'))\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(128, kernel_regularizer='l1_l2', kernel_constraint=tf.keras.constraints.MaxNorm(max_value=2, axis=0), kernel_initializer=HeNormal(), activation='elu'))\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(64, kernel_regularizer='l1_l2', kernel_constraint=tf.keras.constraints.MaxNorm(max_value=2, axis=0), kernel_initializer=HeNormal(), activation='elu'))\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1, kernel_initializer=HeNormal(), activation='sigmoid'))\n",
    "    opt = Adadelta()\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy', 'AUC', f1])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4 elu + adadelta * batch norm\n",
    "model16 = define_model16()\n",
    "checkpoint_path16 = \"training_16/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path16)\n",
    "cp_callback16 = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path16,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "log_dir16 = \"logs/model16/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback16 = tf.keras.callbacks.TensorBoard(log_dir=log_dir16, histogram_freq=1)\n",
    "\n",
    "early_stop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model16.fit(train_set, train_labels, validation_data = (valid_set, valid_labels), epochs=5, callbacks=[cp_callback16, tensorboard_callback16, early_stop_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model16.save('saved_model/model16')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 17 - 4 leaky relu He init + sigmoid He init + Adadelta + Batch norm + Dropout + Early Stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model17():     ### 5 elu\n",
    "    model = Sequential()\n",
    "    #model.add(Dense(1024, kernel_initializer=HeNormal(), activation='elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(Dense(512, kernel_initializer=HeNormal(), activation=tf.keras.layers.LeakyReLU()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(Dense(256, kernel_initializer=HeNormal(), activation=tf.keras.layers.LeakyReLU()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(Dense(128, kernel_initializer=HeNormal(), activation=tf.keras.layers.LeakyReLU()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(Dense(64, kernel_initializer=HeNormal(), activation=tf.keras.layers.LeakyReLU()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(Dense(1, kernel_initializer=HeNormal(), activation='sigmoid'))\n",
    "    opt = Adadelta()\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy', 'AUC', f1])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4 elu + adadelta * batch norm\n",
    "model17 = define_model17()\n",
    "checkpoint_path17 = \"training_17/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path17)\n",
    "cp_callback17 = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path17,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "log_dir17 = \"logs/model17/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback17 = tf.keras.callbacks.TensorBoard(log_dir=log_dir17, histogram_freq=1)\n",
    "\n",
    "early_stop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model17.fit(train_set, train_labels, validation_data = (valid_set, valid_labels), epochs=10, callbacks=[cp_callback17, tensorboard_callback17, early_stop_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model17.fit(train_set, train_labels, validation_data = (valid_set, valid_labels), epochs=10, callbacks=[cp_callback17, tensorboard_callback17, early_stop_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model17.fit(train_set, train_labels, validation_data = (valid_set, valid_labels), epochs=10, callbacks=[cp_callback17, tensorboard_callback17, early_stop_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model17.save('saved_model/model17')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 18 - 4 leaky relu He init + sigmoid He init + Adadelta + Batch norm + Dropout + l1 l2 + Early Stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model18():     ### 5 elu\n",
    "    model = Sequential()\n",
    "    #model.add(Dense(1024, kernel_initializer=HeNormal(), activation='elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(Dense(512, kernel_regularizer='l1_l2', kernel_initializer=HeNormal(), activation=tf.keras.layers.LeakyReLU()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(Dense(256, kernel_regularizer='l1_l2', kernel_initializer=HeNormal(), activation=tf.keras.layers.LeakyReLU()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(Dense(128, kernel_regularizer='l1_l2', kernel_initializer=HeNormal(), activation=tf.keras.layers.LeakyReLU()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(Dense(64, kernel_regularizer='l1_l2', kernel_initializer=HeNormal(), activation=tf.keras.layers.LeakyReLU()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(Dense(1, kernel_initializer=HeNormal(), activation='sigmoid'))\n",
    "    opt = Adadelta()\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy', 'AUC', f1])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4 elu + adadelta * batch norm\n",
    "model18 = define_model18()\n",
    "checkpoint_path18 = \"training_18/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path18)\n",
    "cp_callback18 = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path18,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "log_dir18 = \"logs/model18/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback18 = tf.keras.callbacks.TensorBoard(log_dir=log_dir18, histogram_freq=1)\n",
    "\n",
    "early_stop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model18.fit(train_set, train_labels, validation_data = (valid_set, valid_labels), epochs=5, callbacks=[cp_callback18, tensorboard_callback18, early_stop_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model18.fit(train_set, train_labels, validation_data = (valid_set, valid_labels), epochs=5, callbacks=[cp_callback18, tensorboard_callback18, early_stop_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model18.fit(train_set, train_labels, validation_data = (valid_set, valid_labels), epochs=10, callbacks=[cp_callback18, tensorboard_callback18, early_stop_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading & compiling the model from save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_final = tf.keras.models.load_model('saved_model/model17', compile=False)\n",
    "model_final.compile(optimizer=Adadelta(), loss='binary_crossentropy', metrics=['accuracy', 'AUC', f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating small test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CREATION OF SMALL TEST SET\n",
    "# from os import listdir\n",
    "# from numpy import asarray\n",
    "# from numpy import save\n",
    "# from keras.preprocessing.image import load_img\n",
    "# from keras.preprocessing.image import img_to_array\n",
    "# # define location of dataset\n",
    "# folder = 'test/'\n",
    "# photos, labels = list(), list()\n",
    "# # enumerate files in the directory\n",
    "# i=0\n",
    "# for file in listdir(folder):\n",
    "#     photo = load_img(folder + file, target_size=(200, 200))\n",
    "#     # convert to numpy array\n",
    "#     photo = img_to_array(photo)\n",
    "#     #store\n",
    "#     photos.append(photo)\n",
    "#     i += 1\n",
    "#     if i > 20:\n",
    "#         break\n",
    "# # convert to a numpy arrays\n",
    "# photos = asarray(photos)\n",
    "# print(photos.shape)\n",
    "# # save the reshaped photos\n",
    "# save('test_photos.npy', photos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = load('test_photos.npy').reshape(21, 120000) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting classes for the test images and plotting them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions for test set\n",
    "prediction = tf.make_tensor_proto(model_final(test_set[0:20]))\n",
    "prediction = tf.make_ndarray(prediction)\n",
    "pyplot.figure(figsize=(15,15))\n",
    "for i in range(20):\n",
    "    pyplot.subplot(5,4,i+1)\n",
    "    pyplot.xticks([])\n",
    "    pyplot.yticks([])\n",
    "    pyplot.grid(False)\n",
    "    pyplot.imshow(test_set[i].reshape(200,200,3))\n",
    "    if prediction[i][0] >= 0.5:\n",
    "        pyplot.xlabel(\"cat\")\n",
    "    else:\n",
    "        pyplot.xlabel(\"dog\")\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same predictions using predict_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions for test set\n",
    "prediction = model_final.predict_classes(test_set)\n",
    "pyplot.figure(figsize=(15,15))\n",
    "for i in range(20):\n",
    "    pyplot.subplot(5,4,i+1)\n",
    "    pyplot.xticks([])\n",
    "    pyplot.yticks([])\n",
    "    pyplot.grid(False)\n",
    "    pyplot.imshow(test_set[i].reshape(200,200,3))\n",
    "    if prediction[i][0] >= 0.5:\n",
    "        pyplot.xlabel(\"cat\")\n",
    "    else:\n",
    "        pyplot.xlabel(\"dog\")\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
